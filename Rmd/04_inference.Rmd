---
title: "Inference"
author: "Matteo Courthoud"
type: book
weight: 4
date: 2021-10-29
bibliography: references.bib
link-citations: true
output: 
  ioslides_presentation:
    widescreen: true
    smaller: true
    transition: 0
    slide_level: 3
    css: custom.css
  ml_notebook: 
    toc: true
    toc_depth: 2
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    toc_collapsed: true
  md_document:
    variant: markdown_mmd
    preserve_yaml: true
---

## Statistical Models

### Definition

A **statistical model** is a set of probability distributions $\lbrace P \rbrace$. 

More precisely, a **statistical model over data** $D \in \mathcal{D}$ is a set of probability distribution over datasets $D$ which takes values in $\mathcal{D}$.

Suppose you have regression data $\lbrace x_i , y_i \rbrace _ {i=1}^N$ with $\mathbb{x}_i \in \mathbb{R}^p$ and $y_i \in \mathbb{R}$. The statistical model is

$$
\Big\lbrace   P : y_i = f(x_i) + \varepsilon_i, \ x_i \sim F_x , \ \varepsilon_i \sim F _\varepsilon , \ \varepsilon_i \perp x_i , \ f \in C^2 (\mathbb{R}^p) \Big\rbrace
$$

> **In words**: the statistical model is the set of distributions $P$ such that an additive decomposition of $y_i$ as $f(x_i) + \varepsilon_i$ exists for some $x_i$; where $f$ is twice continuously differentiable.



### Parametrization

A statistical model parameterized by $\theta \in \Theta$ is **well specified** if the data generating process corresponds to some $\theta_0$ and $\theta_0 \in \Theta$. Otherwise, the statistical model is **misspecified**.

A statistical model can be parametrized as $\mathcal{F} = \lbrace   P_\theta \rbrace _ {\lbrace \theta \in \Theta \rbrace }$. 

We can class statistical models into 3 classes

- **Parametric**: the stochastic features of the model are completly specified up to a finite dimensional parameter: $\lbrace   P_\theta \rbrace _ { \lbrace   \theta \in \Theta \rbrace }$ with $\Theta \subseteq \mathbb{R}^k, k<\infty$;
- **Semiparametric**: it is a partially specified model, e.g.,  $\lbrace   P_\theta \rbrace  _ { \lbrace   \theta \in \Theta, \gamma \in \Gamma \rbrace }$ with $\Theta$ of finite dimension and $\Gamma$ of infinite dimension;
- **Non parametric**: there is no finite dimensional component of the model. 



### Estimation

Let $\mathcal{D}$ be the set of possible data realizations. Let $D \in \mathcal{D}$ be your data. Let $\mathcal{F}$ be a statistical model indexed by some parameter $\theta \in \Theta$. An **estimator** is a map 
$$
\mathcal{D} \to \mathcal{F} \quad , \quad  D \mapsto \hat{\theta}
$$

An estimator is a map from the set of data realizations to the set of statistical models.

It takes as inputs a dataset $D$ and outputs a parameter estimate $\hat \theta$.



### Properties of Estimators

Suppose you have a statistical model parametrized by $\theta$ and an estimator $\hat{\theta}$. The **bias** of $\hat{\theta}$ relative to $\theta$ is given by
$$
Bias _ {\theta} (\hat{\theta}) = \mathbb{E} _ {x|\theta} [\hat{\theta} ] - \theta = \mathbb{E} _ {x|\theta} [\hat{\theta} - \theta]
$$

Let $\hat{\theta}$ be an estimator for $\theta_0$. We say $\hat{\theta}$ is an **unbiased** estimator for $\theta$ if $\mathbb{E}[\hat{\theta}] = \theta_0$.



### Inference

Let $\alpha > 0$ be a small tolerance. Statistical **inference** is a map into subsets of $\mathcal{F}$ given by
$$
\mathcal{D} \to \mathcal{G} \subseteq \mathcal{F}: \min _ \theta P_\theta (\mathcal{G} | \theta \in \mathcal{G}) \geq 1-\alpha
$$

> **In words**
>
> - Inference maps datasets into sets of models
> - The set contains only models that generate the observed data with high probability
> - I.e. at least $1-\alpha$



### DGP

A **data generating process** (DGP) is a single statistical distribution over $\mathcal{D}$.



## Hypotesis Testing

### Hypothesis

A **statistical hypothesis** $H_0$, is a subset of a statistical model, $\mathcal K \subset \mathcal F$. 

If $\mathcal F$ is the statistical model and $\mathcal K$ is the statistical hypothesis, we use the notation $H_0 : P \in \mathcal K$.



> **Example**
>
> Common hypothesis are
>
> - A single coefficient being equal to zero, $\beta_k = c \in \mathbb R$
> - Multiple linear combination of coefficients being equal to some values: $\boldsymbol R' \beta = r \in \mathbb R^p$



### Test

A **hypothesis test** $T$ is a map from the space of datasets to a decision, rejection (0) or acceptance (1)
$$
\mathcal D \to \lbrace 0, 1 \rbrace \quad, \quad D \mapsto T
$$


>Generally, we are interested in understanding whether it is likely that data $D$ are drawn from a model $\mathcal K$ or not. 
>
>A hypothesis test, $T$ is our tool for deciding whether the hypothesis is consistent with the data.
>
>- $T(D) = 0 \to$ fail to reject $H_0$ and test inconclusive 
>- $T (D) = 1 \to$ reject $H_0$ and D is inconsistent with any $P \in \mathcal K$



### Errors

Let $\mathcal K \subset \mathcal F$ be a statistical hypothesis and $T$ a hypothesis test.

1. A **Type I error** is an event $T(D)=1$ under $P \in \mathcal K$. 
   - In words: rejecting the null hypothesis, when it is is true
2. A **Type II error** is an event $T(D)=0$ under $P \in \mathcal K^C$. 
   - In words: not rejecting the null hypothesis, when it is false

The corresponding probability of a type I error is called **size**. 

The corresponding probability of a type II error is called **power** (against the alternative P).



### Type I Error and Test Size

Test **size** is the probability of a Type I error, i.e.
$$
\Pr \Big[ \text{ Reject } H_0 \Big| H_0 \text{ is true } \Big] = \Pr \Big[ T(D)=1 \Big| P \in \mathcal K \Big]
$$
A primary goal of test construction is to limit the incidence of Type I error by bounding the size of the test.



### Type II Error and Power

Test **power** is the probability of a Type II error, i.e.
$$
\Pr \Big[ \text{ Not Reject } H_0 \Big| H_0 \text{ is false } \Big] = \Pr \Big[ T(D)=0 \Big| P \in \mathcal K^C \Big]
$$
In the dominant approach to hypothesis testing the goal of test construction is to have high power subject to the constraint that the size of the test is lower than the pre-specified significance level.



### Statistical Significance

TBD



### Recap

We now summarize the main features of hypothesis testing. 

1. Select a significance level $\alpha$.
2. Select a test statistic $T$ with asymptotic distribution $T\to \xi$ under $H_0$.
3. Set the asymptotic critical value $c$ so that 1−*G*(*c*)=α, where *G* is the distribution function of $\xi$.
4. Calculate the asymptotic p-value *p*=1−*G*(*T*).
5. Reject $H_0$ if *T* > *c*, or equivalently *p* < α.
6. Accept $H_0$ if *T* ≤ *c*, or equivalently *p* ≥ α.
7. Report $p$ to summarize the evidence concerning $H_0$ versus $H_1$.



### Examples

Let's focus three hypotheses:

1. $\beta_k = c \in \mathbb R$
2. $\boldsymbol R' \beta = r \in \mathbb R^p$



### t-test

Consider the testing problem $H_0 : \beta_k = c$, where $c$ is a presepecified value under the null.

The t-statistic for this problem is defined by
$$
t_{k}:=\frac{\hat \beta_{k} - c}{\sigma_{\hat \beta_{k}}}
$$
In the testing procedure above, the sampling distribution under the null $H_0$ is given by
$$
t_k \sim t_{n-K}
$$
Where $t_{n-K}$ denotes the t-distribution with $n-K$ degress of freedom.



### F-test

Consider the testing problem $\boldsymbol R' \beta = r$, where $\boldsymbol R  \in \mathbb R^{p+K}$ is a presepecified set of linear combinations and $r \in R^p$  is a restriction vector. 

The F-statistic for this problem is given by
$$
F:=\frac{(R b-r)^{\prime}\left[R\left(X^{\prime} X\right) R^{\prime}\right]^{-1}(R b-r) / p}{s^{2}}
$$
In the testing procedure above, the sampling distribution under the null $H_0$ is given by
$$
F \sim F_{p, n-K}
$$
Where $F_{p, n-K}$ denotes the t-distribution with $n-K$ degress of freedom.



### Confidence Intervals

TBD



### Minimum Distance Tests

TBD







## Asymptotics



